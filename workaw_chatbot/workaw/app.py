import os
import re
import fitz  # PyMuPDF
import google.generativeai as genai
import streamlit as st
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import dotenv

# --- ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° Import Prompt ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ Default) ---
try:
    from prompt import PROMPT_WORKAW
except ImportError:
    PROMPT_WORKAW = "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏£‡∏≤‡∏ü‡∏¥‡∏Å ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏ö‡∏°‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"

# --- ‡πÇ‡∏´‡∏•‡∏î Config ---
dotenv.load_dotenv()
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')

if not GOOGLE_API_KEY:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå .env")
    st.stop()

genai.configure(api_key=GOOGLE_API_KEY)

# --- Path Config ---
current_dir = os.path.dirname(os.path.abspath(__file__))
pdf_filename = os.path.join(current_dir, "Graphic.pdf")

# --- Model Config (Temperature 0 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥) ---
generation_config = {
    "temperature": 0.0,
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 2048,
    "response_mime_type": "text/plain",
}

SAFETY_SETTINGS = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE
}

# --- CSS ‡∏ò‡∏µ‡∏°‡∏û‡∏≤‡∏™‡πÄ‡∏ó‡∏• ---
page_bg_img = """
<style>
[data-testid="stAppViewContainer"] {
    background-image: linear-gradient(to bottom right, #E0C3FC, #FFD1DC, #BDE0FE);
}
[data-testid="stHeader"] {
    background-color: rgba(0, 0, 0, 0);
}
[data-testid="stSidebar"] {
    background-color: #F3E5F5;
}
</style>
"""
st.markdown(page_bg_img, unsafe_allow_html=True)

# --- ‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏ö‡∏ö Hybrid (Cache ‡πÑ‡∏ß‡πâ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡∏≠‡πà‡∏≤‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á) ---
@st.cache_resource(show_spinner="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå PDF...")
def load_pdf_data_hybrid(file_path):
    text_content = ""
    page_images_map = {} 
    
    if os.path.exists(file_path):
        try:
            doc = fitz.open(file_path)
            
            for i, page in enumerate(doc):
                page_num = i + 1
                text = page.get_text()
                # ‡πÉ‡∏™‡πà Marker ‡∏ä‡∏±‡∏î‡πÜ ‡πÉ‡∏´‡πâ AI ‡πÄ‡∏´‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡∏´‡∏ô‡πâ‡∏≤
                text_content += f"\n[--- Page {page_num} START ---]\n{text}\n[--- Page {page_num} END ---]\n"
                
                # 1. ‡∏•‡∏≠‡∏á‡∏ï‡∏±‡∏î‡∏£‡∏π‡∏õ (Crop)
                image_blocks = [b for b in page.get_text("blocks") if b[6] == 1]
                saved_images = []
                
                if image_blocks:
                    for img_block in image_blocks:
                        rect = fitz.Rect(img_block[:4])
                        if rect.width > 50 and rect.height > 50: 
                            rect.x0 -= 5; rect.y0 -= 5; rect.x1 += 5; rect.y1 += 5
                            try:
                                pix_crop = page.get_pixmap(matrix=fitz.Matrix(3, 3), clip=rect)
                                saved_images.append(pix_crop.tobytes("png"))
                            except:
                                pass
                
                # 2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏π‡∏õ ‡πÉ‡∏´‡πâ Capture ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏ô‡πâ‡∏≤
                if not saved_images:
                    pix_full = page.get_pixmap(matrix=fitz.Matrix(2, 2))
                    saved_images.append(pix_full.tobytes("png"))

                if saved_images:
                    page_images_map[page_num] = saved_images
                
            return text_content, page_images_map
        except Exception as e:
            print(f"Error reading PDF: {e}")
            return "", {}
    else:
        return "", {}

# --- ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ---
pdf_text, pdf_hybrid_images = load_pdf_data_hybrid(pdf_filename)

if not pdf_text:
    st.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {pdf_filename} ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤ (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå)")
else:
    pass # ‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏Å‡∏ï‡∏¥

# --- Prompt (Strict Mode) ---
FULL_SYSTEM_PROMPT = f"""
{PROMPT_WORKAW}

**CRITICAL INSTRUCTIONS FOR ACCURACY:**
1. Use ONLY the information provided in the CONTEXT below. Do NOT use outside knowledge.
2. **Finding the correct Page Number:** - The context is marked with `[--- Page X START ---]` and `[--- Page X END ---]`.
   - When you find the answer text, look immediately ABOVE it to see which "Page START" tag it belongs to.
   - You MUST use that specific Page number.
3. **Citation Format:**
   - At the end of your answer, you MUST append **[PAGE: number]**.
   - Example: "‡∏ß‡∏á‡∏•‡πâ‡∏≠‡∏™‡∏µ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ 12 ‡∏™‡∏µ [PAGE: 14]"
   - If the answer spans multiple pages, cite the one with the most relevant image or detail.
4. If the answer is not in the context, state: "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ñ‡∏£‡∏±‡∏ö".

----------------------------------------
CONTEXT (‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£):
{pdf_text}
----------------------------------------
"""

# --- üî• ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ï‡∏≤‡∏°‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå User) üî• ---
@st.cache_resource(show_spinner="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏°‡∏≠‡∏á AI...")
def setup_gemini_model():
    # ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡πà‡∏á (‡∏à‡∏≤‡∏Å‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏ä‡πá‡∏Ñ‡∏°‡∏≤)
    candidate_models = [
        "gemini-2.5-flash",         # ‡∏ï‡∏±‡∏ß‡πÄ‡∏ó‡∏û ‡πÉ‡∏´‡∏°‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        "gemini-2.0-flash",         # ‡∏ï‡∏±‡∏ß‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£
        "gemini-flash-latest",      # ‡∏ï‡∏±‡∏ß‡∏™‡∏≥‡∏£‡∏≠‡∏á (Auto Update)
        "gemini-2.0-flash-lite"     # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡πá‡∏Å ‡πÄ‡∏£‡πá‡∏ß
    ]

    for model_name in candidate_models:
        try:
            print(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏≠‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠: {model_name}...")
            test_model = genai.GenerativeModel(
                model_name=model_name,
                safety_settings=SAFETY_SETTINGS,
                generation_config=generation_config,
                system_instruction=FULL_SYSTEM_PROMPT
            )
            # Ping Test
            test_model.generate_content("Hi")
            print(f"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model_name}")
            return test_model, model_name
        except Exception as e:
            print(f"‚ùå {model_name} Error: {e}")
            continue
            
    return None, None

# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô
model, active_model_name = setup_gemini_model()

if model is None:
    st.error("üö® ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Gemini ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ (‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏ä‡πá‡∏Ñ API Key ‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÉ‡∏ô 1 ‡∏ô‡∏≤‡∏ó‡∏µ)")
    st.stop()

# --- UI Streamlit ---
def clear_history():
    st.session_state["messages"] = [
        {"role": "model", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡∏ô‡πâ‡∏≠‡∏á Graphic Bot ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏¥‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≤ üé®‚ú®"}
    ]
    st.rerun()

with st.sidebar:
    st.success(f"ü§ñ Connected: {active_model_name}") 
    if st.button("üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢"):
        clear_history()

st.title("‚ú® ‡∏ô‡πâ‡∏≠‡∏á Graphic Bot üé®")

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "model", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡∏ô‡πâ‡∏≠‡∏á Graphic Bot ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏¥‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≤ üé®‚ú®"}
    ]

# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
for msg in st.session_state["messages"]:
    avatar_icon = "üê∞" if msg["role"] == "user" else "ü¶Ñ"
    with st.chat_message(msg["role"], avatar=avatar_icon):
        st.write(msg["content"])
        if "image_list" in msg and msg["image_list"]:
             for idx, img_data in enumerate(msg["image_list"]):
                st.image(img_data, caption=f"üñºÔ∏è ‡∏†‡∏≤‡∏û‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤ {msg.get('page_num_ref')}", use_container_width=True)

# ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
if prompt := st.chat_input():
    st.session_state["messages"].append({"role": "user", "content": prompt})
    st.chat_message("user", avatar="üê∞").write(prompt)

    def generate_response():
        history_api = [
            {"role": msg["role"], "parts": [{"text": msg["content"]}]}
            for msg in st.session_state["messages"] if "content" in msg
        ]

        try:
            # ‡∏¢‡πâ‡∏≥‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            strict_prompt = f"{prompt}\n(‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏•‡∏±‡∏ö: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å Context ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÅ‡∏•‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏•‡∏Ç‡∏´‡∏ô‡πâ‡∏≤ [PAGE: x] ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á)"
            
            chat_session = model.start_chat(history=history_api)
            response = chat_session.send_message(strict_prompt)
            response_text = response.text
            
            # ‡∏î‡∏∂‡∏á‡πÄ‡∏•‡∏Ç‡∏´‡∏ô‡πâ‡∏≤
            page_match = re.search(r"\[PAGE:\s*(\d+)\]", response_text)
            images_to_show = []
            ref_page_num = None
            p_num = None 
            
            if page_match:
                try:
                    p_num = int(page_match.group(1))
                    ref_page_num = p_num
                    if p_num in pdf_hybrid_images:
                        images_to_show = pdf_hybrid_images[p_num]
                except:
                    pass

            with st.chat_message("model", avatar="ü¶Ñ"):
                st.write(response_text)
                if images_to_show:
                    for idx, img_data in enumerate(images_to_show):
                        st.image(img_data, caption=f"üñºÔ∏è ‡∏†‡∏≤‡∏û‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤ {p_num}", use_container_width=True)
            
            msg_data = {"role": "model", "content": response_text}
            if images_to_show:
                msg_data["image_list"] = images_to_show 
                msg_data["page_num_ref"] = ref_page_num
                
            st.session_state["messages"].append(msg_data)

        except Exception as e:
            st.error(f"‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á: {e}")

    generate_response()